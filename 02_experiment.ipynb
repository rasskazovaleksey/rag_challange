{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "475427246e8856ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T18:24:44.726342Z",
     "start_time": "2025-02-26T18:24:44.681794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/cca42744d1a97475ccd14a5c2b98876b6d379982.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 3293\n",
      "Number of existing documents in DB: 0\n",
      "Adding new documents: 3293\n",
      "Progress: 1/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/91aca730786f67b17ddcdb92319f859c5745ae74.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1178\n",
      "Number of existing documents in DB: 3293\n",
      "Adding new documents: 1178\n",
      "Progress: 2/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/7c55d7900a241e732c145687598d43c915a678f9.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1539\n",
      "Number of existing documents in DB: 4471\n",
      "Adding new documents: 1539\n",
      "Progress: 3/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/9938e66d5f0b65c66c8a404f02c1301d32991666.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1387\n",
      "Number of existing documents in DB: 6010\n",
      "Adding new documents: 1387\n",
      "Progress: 4/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/a6f23184a87f3343f17e8e8ed08f604615cdefc1.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1697\n",
      "Number of existing documents in DB: 7397\n",
      "Adding new documents: 1697\n",
      "Progress: 5/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/c51f3c5aff7bea6fbc0bb7537838fa2f44f35c23.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1746\n",
      "Number of existing documents in DB: 9094\n",
      "Adding new documents: 1746\n",
      "Progress: 6/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/30b729c124a24ff21f37431dab6b58dfe7ba56fa.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 502\n",
      "Number of existing documents in DB: 10840\n",
      "Adding new documents: 502\n",
      "Progress: 7/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/f75ff9d631e7efdb86db68ab8ba395de221d9019.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 2354\n",
      "Number of existing documents in DB: 11342\n",
      "Adding new documents: 2354\n",
      "Progress: 8/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/ea4b61f74a604df117176e74b11f5780fb473a31.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1989\n",
      "Number of existing documents in DB: 13696\n",
      "Adding new documents: 1989\n",
      "Progress: 9/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/69b472e4c05986db72ff8e547bb220e2d222b7ef.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 3860\n",
      "Number of existing documents in DB: 15685\n",
      "Adding new documents: 3860\n",
      "Progress: 10/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/f973dd219c534accb0d4e72d8e12f51284d48d10.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1728\n",
      "Number of existing documents in DB: 19545\n",
      "Adding new documents: 1728\n",
      "Progress: 11/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/58b196e02c2d9749d968a29039e9c2b29d3d31e1.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1605\n",
      "Number of existing documents in DB: 21273\n",
      "Adding new documents: 1605\n",
      "Progress: 12/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/a34c22665bada80d76b98b0e794096aefc06758a.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 3924\n",
      "Number of existing documents in DB: 22878\n",
      "Adding new documents: 3924\n",
      "Progress: 13/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/79ffb9b8682aa565172233c070a47d944464644c.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 2661\n",
      "Number of existing documents in DB: 26802\n",
      "Adding new documents: 2661\n",
      "Progress: 14/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/601aba58deffc81230c837404aa883de0d1dde1c.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 462\n",
      "Number of existing documents in DB: 29463\n",
      "Adding new documents: 462\n",
      "Progress: 15/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/49a9bf0542f3e5ff0250064bfed4369ecf6c8a09.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 916\n",
      "Number of existing documents in DB: 29925\n",
      "Adding new documents: 916\n",
      "Progress: 16/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/5ac3ccdec033f81fab4c2ed9ae86553f4904a450.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 2388\n",
      "Number of existing documents in DB: 30841\n",
      "Adding new documents: 2388\n",
      "Progress: 17/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/cd9239df47b2f0addd9cdd50d0fab4494414bba5.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1465\n",
      "Number of existing documents in DB: 33229\n",
      "Adding new documents: 1465\n",
      "Progress: 18/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/b03044c60d02a0a5557f95f6afb59e5ffc487799.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1219\n",
      "Number of existing documents in DB: 34694\n",
      "Adding new documents: 1219\n",
      "Progress: 19/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/42f03832077a92b3b34855cb7f9ef93563143838.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1681\n",
      "Number of existing documents in DB: 35913\n",
      "Adding new documents: 1681\n",
      "Progress: 20/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/9cc771c2171bacc138cda4e7d68b8b427a514d81.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 3896\n",
      "Number of existing documents in DB: 37594\n",
      "Adding new documents: 3896\n",
      "Progress: 21/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/61c082634d8902124bd48f55ab93ca0fb0599462.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 2455\n",
      "Number of existing documents in DB: 41490\n",
      "Adding new documents: 2455\n",
      "Progress: 22/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/63688d5d0b4f12e9f847c5407439a1ec46047a4a.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 851\n",
      "Number of existing documents in DB: 43945\n",
      "Adding new documents: 851\n",
      "Progress: 23/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/69a9dcb0bb6a46e2ff9f969d035e1774a2d49ef1.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1727\n",
      "Number of existing documents in DB: 44796\n",
      "Adding new documents: 1727\n",
      "Progress: 24/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/62367207e1e1747a92aaba83055fea26e9a2d684.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 693\n",
      "Number of existing documents in DB: 46523\n",
      "Adding new documents: 693\n",
      "Progress: 25/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/dda7722dd2e90c9942ed383957b527873cc74174.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 683\n",
      "Number of existing documents in DB: 47216\n",
      "Adding new documents: 683\n",
      "Progress: 26/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/56262704bde6b584dcebfa644faa23a953498a79.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1893\n",
      "Number of existing documents in DB: 47899\n",
      "Adding new documents: 1893\n",
      "Progress: 27/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/7820b6e9487202b30f2883a6df91ae76f9461f2f.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1855\n",
      "Number of existing documents in DB: 49792\n",
      "Adding new documents: 1855\n",
      "Progress: 28/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/f393170837ab7636d83fdc105279dfc61ebeb017.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1037\n",
      "Number of existing documents in DB: 51647\n",
      "Adding new documents: 1037\n",
      "Progress: 29/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/d3a834539b046a49708161a6c0d35aad29dd15ec.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1350\n",
      "Number of existing documents in DB: 52684\n",
      "Adding new documents: 1350\n",
      "Progress: 30/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/20c4badd4303f7aba1a298d84be3722fa84e0c67.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 2391\n",
      "Number of existing documents in DB: 54034\n",
      "Adding new documents: 2391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 19 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 31 0 (offset 0)\n",
      "Ignoring wrong pointing object 33 0 (offset 0)\n",
      "Ignoring wrong pointing object 41 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 117 0 (offset 0)\n",
      "Ignoring wrong pointing object 128 0 (offset 0)\n",
      "Ignoring wrong pointing object 133 0 (offset 0)\n",
      "Ignoring wrong pointing object 138 0 (offset 0)\n",
      "Ignoring wrong pointing object 144 0 (offset 0)\n",
      "Ignoring wrong pointing object 149 0 (offset 0)\n",
      "Ignoring wrong pointing object 157 0 (offset 0)\n",
      "Ignoring wrong pointing object 168 0 (offset 0)\n",
      "Ignoring wrong pointing object 170 0 (offset 0)\n",
      "Ignoring wrong pointing object 197 0 (offset 0)\n",
      "Ignoring wrong pointing object 199 0 (offset 0)\n",
      "Ignoring wrong pointing object 211 0 (offset 0)\n",
      "Ignoring wrong pointing object 217 0 (offset 0)\n",
      "Ignoring wrong pointing object 222 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 31/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/8dd1306c26c63913495fe81dde5180033b39fc44.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 610\n",
      "Number of existing documents in DB: 56425\n",
      "Adding new documents: 610\n",
      "Progress: 32/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/da8afefdc3840175c9f26a4dbbed05e250a342cc.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 2083\n",
      "Number of existing documents in DB: 57035\n",
      "Adding new documents: 2083\n",
      "Progress: 33/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/0a9e39e1d2e176f3a766a0e86af82772f1654a6e.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 2524\n",
      "Number of existing documents in DB: 59118\n",
      "Adding new documents: 2524\n",
      "Progress: 34/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/9b3fa9062a804f0f5a5dbfa46309ed3354cd680b.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 721\n",
      "Number of existing documents in DB: 61642\n",
      "Adding new documents: 721\n",
      "Progress: 35/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/54e625a049a1713eb5a338b64858c06d74e52489.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1118\n",
      "Number of existing documents in DB: 62363\n",
      "Adding new documents: 1118\n",
      "Progress: 36/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/6df434795a611c7fc88c75c728a96e400fc5b74d.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 2009\n",
      "Number of existing documents in DB: 63481\n",
      "Adding new documents: 2009\n",
      "Progress: 37/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/ed55750eae9cb7d893e6484b92496639172717cd.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 2212\n",
      "Number of existing documents in DB: 65490\n",
      "Adding new documents: 2212\n",
      "Progress: 38/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/873f84bbc485e5c04065c9b13b15e7129bd255fe.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 627\n",
      "Number of existing documents in DB: 67702\n",
      "Adding new documents: 627\n",
      "Progress: 39/39\n",
      "Loading documents from ./data/r2.0-test/pdfs/612279ce81b538da24834af47131cc73e8c01a80.pdf...\n",
      "Splitting documents...\n",
      "Appending chunk ids...\n",
      "Filtering documents...\n",
      "Number of chunks: 1356\n",
      "Number of existing documents in DB: 68329\n",
      "Adding new documents: 1356\n"
     ]
    }
   ],
   "source": [
    "from numpy.ma.core import count\n",
    "\n",
    "from lib.EmbeddingProvider import OpenAiEmbeddingProvider\n",
    "\n",
    "from lib.DataRepository import DataRepository\n",
    "from lib.questions import QuestionExtractor\n",
    "\n",
    "chunk_size = 350\n",
    "chunk_overlap = 35\n",
    "repo = DataRepository(embedding=OpenAiEmbeddingProvider(), db_path=f\"./data/db/open_ai_small_{chunk_size}_{chunk_overlap}\", chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "repo.save_by_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d0ace9cb6df7f",
   "metadata": {},
   "source": [
    "# Parce question and find metrics in the question, find similar metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7c7be7ae2e607bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T18:24:44.734206Z",
     "start_time": "2025-02-26T18:24:44.731622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original_question': \"According to the annual report, what is the Operating margin (%) for Altech Chemicals Ltd  (within the last period or at the end of the last period)? If data is not available, return 'N/A'.\", 'metric': 'Operating margin (%)', 'companies': ['Altech Chemicals Ltd'], 'currency': None, 'comparison': None, 'category': 'fin_metric'}\n",
      "['operating profit margin', 'operational margin', 'profit margin (operating)', 'percentage operating profit']\n"
     ]
    }
   ],
   "source": [
    "from lib.questions import QuestionExtractor\n",
    "\n",
    "question = \"According to the annual report, what is the Operating margin (%) for Altech Chemicals Ltd  (within the last period or at the end of the last period)? If data is not available, return 'N/A'.\"\n",
    "kind = \"names\"\n",
    "\n",
    "extractor = QuestionExtractor()\n",
    "extract = extractor.extract(question)\n",
    "print(extract)\n",
    "close_metrics = extractor.get_synonyms(extract[\"metric\"])\n",
    "print(close_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26adbd7f9ea4d670",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T18:24:44.749155Z",
     "start_time": "2025-02-26T18:24:44.745717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sha1': '63688d5d0b4f12e9f847c5407439a1ec46047a4a',\n",
       " 'cur': 'USD',\n",
       " 'company_name': 'Altech Chemicals Ltd',\n",
       " 'major_industry': 'Technology',\n",
       " 'mentions_recent_mergers_and_acquisitions': True,\n",
       " 'has_leadership_changes': False,\n",
       " 'has_layoffs': False,\n",
       " 'has_executive_compensation': True,\n",
       " 'has_rnd_investment_numbers': True,\n",
       " 'has_new_product_launches': True,\n",
       " 'has_capital_expenditures': True,\n",
       " 'has_financial_performance_indicators': True,\n",
       " 'has_dividend_policy_changes': False,\n",
       " 'has_share_buyback_plans': False,\n",
       " 'has_capital_structure_changes': False,\n",
       " 'mentions_new_risk_factors': True,\n",
       " 'has_guidance_updates': False,\n",
       " 'has_regulatory_or_litigation_issues': False,\n",
       " 'has_strategic_restructuring': False,\n",
       " 'has_supply_chain_disruptions': False,\n",
       " 'has_esg_initiatives': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "companiy = extract[\"companies\"][0]\n",
    "with open(\"data/r2.0-test/subset.json\", 'r') as file:\n",
    "    subset = json.load(file)\n",
    "filered = list(filter(lambda x: x[\"company_name\"] == companiy, subset))[0]\n",
    "filered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9874ee77f157711d",
   "metadata": {},
   "source": [
    "# Find similar metrics in the data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd095eed13384898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T18:24:47.792116Z",
     "start_time": "2025-02-26T18:24:44.770821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating margin (%)\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "main_metric = extract[\"metric\"]\n",
    "print(main_metric)\n",
    "file_filter = { \"source\" : f\"./data/r2.0-test/pdfs/{filered[\"sha1\"]}.pdf\" }\n",
    "main_results = repo.query(main_metric, k=10, f=file_filter) # start with main metric from the question\n",
    "\n",
    "main_metric = extract[\"metric\"]\n",
    "smaller_results = [] # start with main metric from the question\n",
    "for m in close_metrics:\n",
    "    smaller_results += repo.query(m, k=5) # find similar metrics\n",
    "search_results = main_results + smaller_results\n",
    "print(len(search_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1caf0f0d4ef75e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T18:24:47.803529Z",
     "start_time": "2025-02-26T18:24:47.798671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(47, {'count': 5, 'score': 1.062661838531494}),\n",
       " (12, {'count': 3, 'score': 0.32247887551784515}),\n",
       " (141, {'count': 3, 'score': 0.39292486508687335}),\n",
       " (25, {'count': 3, 'score': 0.467891405026118}),\n",
       " (2, {'count': 2, 'score': 0.4098067879676819}),\n",
       " (99, {'count': 2, 'score': 0.419970765709877}),\n",
       " (123, {'count': 2, 'score': 0.6258890330791473}),\n",
       " (65, {'count': 2, 'score': 1.069601833820343})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_candidates = {}\n",
    "for doc, score in search_results:\n",
    "    page = doc.metadata[\"page\"]\n",
    "    if page in pages_candidates:\n",
    "        pages_candidates[page][\"count\"] += 1\n",
    "        pages_candidates[page][\"score\"].append(score)\n",
    "    else:\n",
    "        pages_candidates[page] = {\n",
    "            \"count\": 1,\n",
    "            \"score\": [score]\n",
    "        }\n",
    "pages_candidates_filtered = pages_candidates\n",
    "for p in pages_candidates_filtered:\n",
    "    pages_candidates_filtered[p][\"score\"] = sum(pages_candidates_filtered[p][\"score\"]) / pages_candidates_filtered[p][\"count\"]\n",
    "\n",
    "pages_candidates_filtered = sorted(\n",
    "    pages_candidates.items(),\n",
    "    key=lambda x: (-x[1][\"count\"], x[1][\"score\"])\n",
    ")\n",
    "pages_candidates_filtered[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b032afe3c47fabea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T18:24:52.904357Z",
     "start_time": "2025-02-26T18:24:47.818542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "12\n",
      "25\n",
      "47\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "document_loader = PyPDFLoader(file_filter[\"source\"])\n",
    "doc = document_loader.load()\n",
    "\n",
    "pages = [p for p in doc if p.metadata[\"page\"] in [p for p, _ in pages_candidates_filtered[0:8]]]\n",
    "for p in pages:\n",
    "    print(p.metadata[\"page\"])\n",
    "    p.metadata[\"id\"] = p.metadata[\"page\"]\n",
    "\n",
    "rag = [(p, 0.0) for p in pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6500237fb218139",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T18:24:53.826727Z",
     "start_time": "2025-02-26T18:24:52.930975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N/A'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.Agent import OpenAIAgent\n",
    "\n",
    "agent = OpenAIAgent()\n",
    "agent.query(question, rag, path=\"./prompt/names_prompt.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
